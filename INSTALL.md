The source codes and the results are placed in this repository.
- To access the result present in the paper, please access the `Result.xlsx` file and go to the corresponding sheet, e.g., if you want to check the results related to the Table 1, then go to `Table 1` sheet or if you want to check the results related to the Table 2 upper half, then go to the `Table2_Up` sheet.
- The source codes are categorized based on the experimental setup. We have proposed six different approaches to decompose a deep neural network (DNN) into modules. The source code of each technique has been carefully placed under the corresponding folder. For example, for `Tangling Identification: Imbalance (TI-I)`, the code is in `Approach 1 (TI-I)`. Within each folder, there are codes for all the datasets, MNIST, EMNIST, FMNIST, and KMNIST. Since, for each dataset, we have used four different structure of the handmade models, e.g., for MNIST, MNIST-1, MNIST-2, MNIST-3, and MNIST-4. A detailed description of the setup can be found in the paper. For each model and dataset, there is a folder with the source code. For experiments with MNIST-1, the source code can be found under `<approach>\MNIST\MNIST-1`. For each such experiment, we have the trained model and the decomposed modules saved in .h5 format. Since the training and decomposing takes significant time, the trained model and the modules can be reused by simply using the corresponding files. For example, MNIST-1 has one file mnist.h5, which the trained model and module0, module1, ..., module9, which are the decomposed modules from the DNN model. To validate the result, one can use the scripts given in the `Scripts` folder. Please use the [requirements](./requirements.txt) to sync with the correct version of the library to execute the code. For reusing the code related to the Table 1 in the paper, please use the `Table1.sh` script. For intra and inter reuse and replacement related results, please use the `Table2-3-Reuse.sh` and `Table4-5-Replacement.sh` respectively.
- The experiments related to the [reuse](./Reuse) and the [replacement](./Replacement) are kept under the corresponding directory. To validate the results, one can either check the `Results.xlsx` or the .txt files provided in the folders, where `outputAcc` stores the accuracy of the reusing or replacing the decomposed modules, `outputAccTrain` stores the training accuracy, `outputSequence` stores the sequence in which the reuse/replacement have been done, and `outputSequenceTrain` stores the sequence in which training occurs. Scripts have been provided to validate the results; however, the training accuracy might change as every time a training occurs, the accuracy of a model cannot be exactly the same as the previous one. In the paper, we have reported an instance of the experiments, and the results from that instance have carefully stored in both .txt format and the .xlsx format.
